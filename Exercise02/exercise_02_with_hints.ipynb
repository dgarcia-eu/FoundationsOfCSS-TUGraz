{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Impact Theory with Twitter Data\n",
    "## Tasks\n",
    "In this assignment you will do the following tasks:\n",
    "1. Connecting to Twitter with the twarc package\n",
    "2. Construct the timelines of Twitter users\n",
    "3. Visualize distributions and scatter plots\n",
    "4. Fit and visualize a regression model\n",
    "5. Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install requirements. \n",
    "\n",
    "The following cell contains all the necessary dependencies needed for this task. If you run the cell everything will be installed.  \n",
    "* [`twarc`](https://twarc-project.readthedocs.io/en/latest/) is a Python package for collecting and archiving Twitter JSON data via the Twitter API. [Here](https://twarc-project.readthedocs.io/en/latest/api/client2/) is the documentation of `twarc`.\n",
    "* [`pandas`](https://pandas.pydata.org/docs/index.html) is a Python package for creating and working with tabular data. [Here](https://pandas.pydata.org/docs/reference/index.html) is the documentation of `pandas`.\n",
    "* [`numpy`](https://numpy.org/) is a Python package for mathematical functions. [Here](https://numpy.org/doc/stable/reference/index.html) is the documentation of `numpy`.\n",
    "* [`matplotlib`](https://matplotlib.org/) is a Python package for creating plots. [Here](https://matplotlib.org/stable/api/index.html) is the documentation of `matplotlib`.\n",
    "* [`sklearn`](https://scikit-learn.org/stable/) is a Python package with different machinelearning algorithms. [Here](https://scikit-learn.org/stable/modules/classes.html) is the documentation of `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install twarc\n",
    "! pip install pandas\n",
    "! pip install numpy\n",
    "! pip install matplotlib\n",
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import requirements\n",
    "The cell below imports all necessary dependancies. Make sure they are installed (see cell above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from twarc import Twarc2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Connecting to Twitter with `twarc`\n",
    "## 1.1 Getting ready with `twarc`\n",
    "First of all you need to create a `Twarc2` instance with your credentials. See [here](https://scholarslab.github.io/learn-twarc/02-twitter-setup.html#accessing-keys-and-tokens) how to get your bearer token (You can generate one in the Key and Tokens section of your app). After that you will be able to access the Twitter API with `twarc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = \"XXX\" # replace the XXX with your bearer token\n",
    "twarc_client = Twarc2(bearer_token=bearer_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now lets use the twitter API. For example, we can get basic information on the Twitter account of the New York Times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(twarc_client.user_lookup([\"nytimes\"], usernames=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a `dictionary` with two keys. One is the `__twarc` key where the value is some information about the `twarc` call. The second and more important key is the `data` key. The value here is a list of dictionaries, where each dictionary contains the data for one user. This contains for example, the username, the id, location and other information, just look through the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Construct the timelines of Twitter users\n",
    "\n",
    "## 2.1 Getting a list of users\n",
    "In this Task choose a list with a few hundred Twitter users, [here](https://docs.google.com/spreadsheets/d/1tcNy1q_eQH3HXGt-0hkmSNEGbcOUiC5si3kZ6-F0pB8/) you can find some example ids of such lists.  \n",
    "Retrive all user informations of every user in the list and save them in a pandas Dataframe. The method [`list_members`](https://twarc-project.readthedocs.io/en/latest/api/client2/#twarc.client2.Twarc2.list_members) of `twarc` will help you here.  \n",
    "Pandas method [`json_normalize`](https://pandas.pydata.org/docs/reference/api/pandas.json_normalize.html) will help you to save the json results from twarc in a flat table.\n",
    "\n",
    "If you do not manage to get the data you can use the provided `users.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here!\n",
    "users = []\n",
    "for user in twarc_client.list_members(list_id = ...): # Enter your choosen list id here\n",
    "    # append the user id to the users list\n",
    "# Normalize the data\n",
    "users = pd.json_normalize(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From those users we are interested on those who have written at least 100 tweets and that have at least 100 followers. From the remaining set sample 100 at random. Check out pandas conditional indexing [here](https://pandas.pydata.org/pandas-docs/dev/user_guide/indexing.html#boolean-indexing). To randomly get 100 users you can use pandas [`sample`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n",
    "users = users[(...) & (...)].sample(100) # Enter both conditions for users who have at least 100 tweets and followers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Downloading timelines\n",
    "Next we want to get the timeline of the users, more specific we want to get the last 200 tweets of each user and the information about the tweets. For this you can use `twarc`'s [`timeline`](https://twarc-project.readthedocs.io/en/latest/api/client2/#twarc.client2.Twarc2.timeline) method. This returns a generator where each element contains all the tweets on one page. The twitter API contains a maximum of 100 tweets per page, since we want to extract the last 200 tweets we need to extract the tweets from the first and second page (or the first and second element in the timeline generator).  \n",
    "For this iterate over all users and then call the `timeline` method (make sure you set `max_results` to 100). Now you can use pythons [`next`](https://docs.python.org/3/library/functions.html#next) function to get the next element in the iterator (The first 100 tweets). To get the second 100 tweets (100 - 200 tweets) you just have to call `next` again.   \n",
    "\n",
    "Save the timeline in a pandas dataframe. Again you should use `json_normalize`to flatten the data.\n",
    "\n",
    "If you do not manage to get the data you can also use the provided `timeline.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here!\n",
    "timeline = []\n",
    "for userID in users.id.values:\n",
    "    data = twarc_client.timeline(user=..., max_results=100) # only 100 tweets per page so calling two times the next element (page) of the iterator to get 200 tweets\n",
    "    # append the data to the timeline list (hint: use the next function two times)\n",
    "timeline = pd.json_normalize(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Aggregating and arranging data\n",
    "With the timeline retrived we want to calculate some metrics from the tweets, especcially the mean retweet count, which is also often refered as the social impact. For this you can use pandas [`groupby`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) method. Group the data by the `author_id` and calculate the mean of the retweet count of each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to merge the users data with the newly created mean retweet informations. For this you have to merge the users dataframe with the just created dataframe with the retweet mean of each user. Use `pandas` [`merge`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) method.    \n",
    "\n",
    "Afterwards remove all unused columns, at the end the dataframe should contain the author ID, name, the follower count and the mean retweet count. \n",
    "\n",
    "Attention: The user id in the timeline dataframe (and later on the retweet mean dataframe) are in column `author_id` and the user id on the user dataframe (created with `list_members`) are in column `id`. You can use the keyword arguments `left_on` and `right_on` to merge the two dataframes by the different user id columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Visualize distributions and scatter plots\n",
    "\n",
    "## 3.1 Distribution of the number of followers\n",
    "Plot the histogram of the number of followers of each users in your dataset. Repeat this with a logarithmic `y` scale. Which one is more skewed?  \n",
    "\n",
    "You can use pandas [`hist`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html) method with the keyword argumnet `log` for logarithmic scale, or you can use matplotlibs [`hist`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html) method (don't forget to first create a figure), again with the keyword argument `log` to plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n",
    "fig, axes = plt.subplots(2, 1,  figsize=(10,10))\n",
    "axes[0].hist(...) # Enter the data for the histogram\n",
    "axes[0].set_title(\"Followers Count\")\n",
    "axes[0].set_ylabel(\"Followers Count\")\n",
    "# add log scale\n",
    "axes[1].hist(...) # Enter the data for the histogram\n",
    "axes[1].set_title(\"Followers Count Logarithmic\")\n",
    "axes[1].set_ylabel(\"Followers Count Logarithmic\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Distribution of social impact\n",
    "\n",
    "Repeat the above task but for the social impact of your users, also look at the logarithmic scale. Again, which one is more skewed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n",
    "fig, axes = plt.subplots(2, 1,  figsize=(10,10))\n",
    "axes[0].hist(...) # Enter the data for the histogram\n",
    "axes[0].set_title(\"Social Impact\")\n",
    "axes[0].set_ylabel(\"Social Impact\")\n",
    "# add log scale\n",
    "axes[1].hist(...) # Enter the data for the histogram\n",
    "axes[1].set_title(\"Social Impact Logarithmic\")\n",
    "axes[1].set_ylabel(\"Social Impact Logarithmic\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Number of followers vs social impact\n",
    "Create a scatter plot with the number of followers of each user on the x axis and the social impact of each user on the y axis. Both axis should be in logarithmic scale. Is there a relationship?  \n",
    "\n",
    "Again you can use pandas [`scatter`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.scatter.html) method with `logx` and `logy` set to true or you can use matplotlibs [`scatter`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html) method. Here you can use the `set_yscale` and `set_xscale` method of the axis to set them to `'log'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n",
    "fig, ax = plt.subplots(1, 1,  figsize=(7,7))\n",
    "ax.scatter(...) # Enter the data for the scatter plot\n",
    "ax.set_title(\"Followers Count vs Social Impact\")\n",
    "ax.set_xlabel(\"Followers Count Logarithmic\")\n",
    "ax.set_ylabel(\"Social Impact Logarithmic\")\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Fit and visualize a regression model\n",
    "\n",
    "## 4.1 Fit a linear model\n",
    "\n",
    "First of all make two new columns on the data frame with the social impact and the follower count. One called `SI` with the logarithm of the amount of retweets, and another called `FC` with the logarithm of the amount of followers. For this you can use numpys log function `np.log(...)`.  \n",
    "\n",
    "Now fit a linear regression model with sklearn. For this use the class [`LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) to create a linear regression instance and then call the `fit` method. `SI` is used as the dependent variable (target) and `FC` as the independent variable (features).  \n",
    "\n",
    "Print the model intercept and coefficient. For this you can use the models attributes `coef_` and `intercept_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n",
    "# add logarithmic values of retweet count to the dataframe\n",
    "follower_social_impact_data[\"SI\"] = follower_social_impact_data[\"public_metrics.retweet_count\"].apply(lambda x: np.log(x))\n",
    "follower_social_impact_data[\"FC\"] = follower_social_impact_data[\"public_metrics.followers_count\"].apply(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n",
    "# create a linear regression model from the dataframe with SI as the dependent variable and FC as the independent variable\n",
    "model = LinearRegression().fit(...) # Enter the data for the linear regression model\n",
    "print(model.coef_, model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Plot the results\n",
    "Now plot the same scatter plot as in 3.3 additional add a line plot which shows the regression line of the model. For this use the intercept and the coefficient (slope). Does the line fit the data as you expected?  \n",
    "\n",
    "It is easier to use matplotlib here to add the line plot to the scatter plot. For the line plot you can use matplotlibs [`plot`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html) method. For the x values you can use numpy's [`np.linspace`](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace) method to evenly space x values in a certain range. The y values can be calculated with the intercept and the slope as follows:  \n",
    "$\n",
    "\\begin{align}\n",
    "    y = slope \\cdot x + intercept\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n",
    "# scatter plot from before add the linear regression line\n",
    "fig, ax = plt.subplots(1, 1,  figsize=(7,7))\n",
    "ax.scatter(...) # Enter the data for the scatter plot\n",
    "ax.set_title(\"Followers Count vs Social Impact\")\n",
    "ax.set_xlabel(\"Followers Count Logarithmic\")\n",
    "ax.set_ylabel(\"Social Impact Logarithmic\")\n",
    "# add the linear regression line\n",
    "x_min = follower_social_impact_data[\"FC\"].min()\n",
    "x_max = follower_social_impact_data[\"FC\"].max()\n",
    "# version with intercept and coef:\n",
    "ax.plot(...) # Enter the data for the linear regression line\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Calculate quality of the fit\n",
    "Calculate the residuals of the model and save them in a vector. This can be done with following formula:\n",
    "$\n",
    "\\begin{align}\n",
    "residual = y_{true} - y_{pred}\n",
    "\\end{align}\n",
    "$\n",
    "where $y_{true}$ are the true values of the dependent variable (in our case `SI`) and $y_{pred}$ are the predicted values with the model. To get the predicted values of the model you can use the [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) method of the model.  \n",
    "\n",
    "Afterwards calculate the variance of the residuals and the variance of the social impact variable. For this you can use numpy's [`var`](https://numpy.org/doc/stable/reference/generated/numpy.var.html) function. Is the variance of the residuals lower than the variance of the dependent variable? By how much in proportion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n",
    "prediction = model.predict(...) # Predict the social impact\n",
    "residual = ... # Calculate the residual\n",
    "print(np.var(residual))\n",
    "print(np.var(follower_social_impact_data[\"SI\"]))\n",
    "print(1 - np.var(residual) / np.var(follower_social_impact_data[\"SI\"])) # Calculate the proportion of variance explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Distribution of residuals\n",
    "Plot the histogram of residuals. Do they look normally distributted?  \n",
    "\n",
    "Again you can use matplotlib as before to plot the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n",
    "# plot histogram of residuals\n",
    "fig, ax = plt.subplots(1, 1,  figsize=(5,5))\n",
    "ax.hist(...) # Plot the residuals\n",
    "ax.set_title(\"Distribution of Residuals\")\n",
    "ax.set_ylabel(\"Residuals\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Bootstrapping\n",
    "\n",
    "## 5.1 One sample\n",
    "For bootsrapping we first look at creating one sample. For this use the follower and social impact dataframe from before and sample random rows with replacement. This again can be done with pandas [`sample`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) method and the keyword argument `replace` set to `True`.  \n",
    "\n",
    "Fit a new linear regression model with this new dataset. What is the value of the coefficient and the intercept now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here!\n",
    "sampled_users = follower_social_impact_data.sample(100, replace=True)\n",
    "single_sample_bs_model = LinearRegression()\n",
    "single_sample_bs_model.fit(sampled_users[[\"FC\"]], sampled_users[\"SI\"])\n",
    "print(single_sample_bs_model.coef_, single_sample_bs_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Many bootstrap samples\n",
    "Now repeat this 10000 times, save the resulting coefficient in a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n",
    "multi_sample_bs_model_coef = []\n",
    "for i in range(10000):\n",
    "    # resample the data\n",
    "\n",
    "    # fit the model\n",
    "\n",
    "    # append the coefficient to the multi_sample_bs_model_coef list\n",
    "multi_sample_bs_model_coef = np.array(multi_sample_bs_model_coef) # Convert to array for simpler use later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Bootstrap histogram\n",
    "\n",
    "Plot a histogram of the values resulting from the permutations and add a vertical line on the value of the coefficient of the original model (from task 4.1). For adding a vertical line to the histogram in matplotlib you can use the [`axvline`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.axvline.html) method.  \n",
    "\n",
    " How far is the line from the center of the histogram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n",
    "# plot histogram of bootstrap coefficients\n",
    "fig, ax = plt.subplots(1, 1,  figsize=(5,5))\n",
    "ax.hist(...) # Plot the multi_sample_bs_model_coef\n",
    "ax.set_title(\"Distribution of Bootstrap Coefficients\")\n",
    "ax.set_ylabel(\"Bootstrap Coefficients\")\n",
    "# add vertical at original model coef\n",
    "ax.axvline(model.coef_, color=\"red\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To learn more\n",
    "* Do you find any relationship between social impact and the amount of followers?\n",
    "* How sure are you that it is larger than zero? How sure are you that it is lower than 1?\n",
    "* Is the value of the relationship within the ranges predicted by Social Impact Theory?\n",
    "* Under that relationship, if I have 1000 followers, how many more followers do I need to double my social impact?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46e2835a142a16ae115bce5fddf19f27ce13b17a4ab8ded638c88ab5ce5171d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

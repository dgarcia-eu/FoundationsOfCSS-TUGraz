{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01196ea9-5dff-4279-b0a7-d9ea286e0c19",
   "metadata": {},
   "source": [
    "# Social Network Analysis of Swiss Politicians on Twitter Data\n",
    "## Tasks\n",
    "In this assignment you will do the following tasks:\n",
    "1. Construct the timelines of Twitter users\n",
    "2. Build social network of retweets\n",
    "3. Calculate assortativity\n",
    "4. Permutation tests\n",
    "5. Community detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aac7b3",
   "metadata": {},
   "source": [
    "### Install requirements. \n",
    "\n",
    "The following cell contains all the necessary dependencies needed for this task. If you run the cell everything will be installed.  \n",
    "\n",
    "* [`twarc`](https://twarc-project.readthedocs.io/en/latest/) is a Python package for collecting and archiving Twitter JSON data via the Twitter API. [Here](https://twarc-project.readthedocs.io/en/latest/api/client2/) is the documentation of `twarc`.\n",
    "* [`pandas`](https://pandas.pydata.org/docs/index.html) is a Python package for creating and working with tabular data. [Here](https://pandas.pydata.org/docs/reference/index.html) is the documentation of `pandas`.\n",
    "* [`numpy`](https://numpy.org/) is a Python package for mathematical functions. [Here](https://numpy.org/doc/stable/reference/index.html) is the documentation of `numpy`.\n",
    "* [`matplotlib`](https://matplotlib.org/) is a Python package for creating plots. [Here](https://matplotlib.org/stable/api/index.html) is the documentation of `matplotlib`.\n",
    "* [`networkx`](https://networkx.org/) is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks. [Here](https://networkx.org/documentation/stable/reference/index.html) is the documentation of `networkx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234eb790-6def-45a2-b436-406eb1be62ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install twarc\n",
    "! pip install pandas\n",
    "! pip install numpy\n",
    "! pip install matplotlib\n",
    "! pip install networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebb2e59",
   "metadata": {},
   "source": [
    "### Import requirements\n",
    "The cell below imports all necessary dependancies. Make sure they are installed (see cell above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e909d35-ff4c-45fc-8642-c2be8d3850c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from twarc import Twarc2\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89432616-10db-4283-997c-90a243f41f60",
   "metadata": {},
   "source": [
    "# 1. Construct the timelines of Twitter users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ff031-6257-4caa-b6b1-464f8399eb48",
   "metadata": {},
   "source": [
    "First connect to the Twitter API using your credentials. See [here](https://scholarslab.github.io/learn-twarc/02-twitter-setup.html#accessing-keys-and-tokens) how to get your bearer token (You can generate one in the Key and Tokens section of your app)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a8bdf3-c0c7-4028-b09e-0b789566b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = \"XXX\" # replace the XXX with your bearer token\n",
    "twarc_client = Twarc2(bearer_token=bearer_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0553fefb-bd51-493e-9378-abfb5793c5d9",
   "metadata": {},
   "source": [
    "Import the file SwissPoliticians.csv and read it as a csv. Take into account that separators are tabs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9df31c-a7ea-4bdf-853b-71cd3bc9fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97045a6-5c13-4c5f-801e-fa11036a8b97",
   "metadata": {},
   "source": [
    "Look up the basic profile information of each user by screenname (see function `user_lookup()` in [twarc2](https://twarc-project.readthedocs.io/en/latest/api/client2/#twarc.client2.Twarc2.user_lookup))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e223bb-fd99-484d-9d5f-e1752fc6a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b451349f-8eec-4534-8057-6e491546c024",
   "metadata": {},
   "source": [
    "Merge the user information you retrieved from Twitter with the party affiliations from the `SwissPoliticians.csv` file. Remove all protected users from the dataset and save the user dataset to disk (users where the `\"protected\"` column is set to True). For the merging you can use `pandas` [`merge`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) method.\n",
    "\n",
    "Hint: convert the screen names in both data frames to lower case, to prevent any merging issues. Here you can use `pandas` [`str.lower`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html) method.\n",
    "\n",
    "You can also use the provided `users.csv` file if you not manage to download and edit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0aa70e-cbc2-4494-b088-69d4a8d36b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17226c56-e6cb-4354-b3d7-be2f38345c89",
   "metadata": {},
   "source": [
    "Now retrieve the all tweets from the last 5 days for each user using [twarc](https://twarc-project.readthedocs.io/en/latest/api/client2/#twarc.client2.Twarc2.timeline)'s `timeline()` function. Since we want to build a retweet network, we need to know the user ID of the original tweet for every retweet. To get this information, we need to request an *[expansion](https://developer.twitter.com/en/docs/twitter-api/expansions)*.\n",
    "\n",
    "It might take a bit to get data. If you run unto the [rate limit](https://developer.twitter.com/en/docs/twitter-api/rate-limits) of the Twitter API, you might have to wait up to 15 min to retrieve all tweets. Twarc will wait and resume the request automatically and print a warning.\n",
    "\n",
    "Save the result in a file called `timelines.csv` so you can reload it at a later point in time.\n",
    "\n",
    "**Note:** if you do not manage to download the tweets, we also provide a `timelines.csv` file for you that includes tweets from July 5 to July 12. You can proceed to the next step to load this dataset and continue working with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc66dc46-ae30-4604-8f01-0b2de1465400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fe3122",
   "metadata": {},
   "source": [
    "since we requested an expansion in the `referenced_tweets.id` field, we have a rather complicated nested JSON structure now. Use the [`ensure_flattened`](https://twarc-project.readthedocs.io/en/latest/api/expansions/) utility from `twarc` to flatten the JSON structure into a more manageable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed8d0f-12a7-49e8-82c0-bb2e4057e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f21bcb",
   "metadata": {},
   "source": [
    "Parse the JSON into a .csv and save it. Use `pandas` [`json_normalize`](https://pandas.pydata.org/docs/reference/api/pandas.json_normalize.html) to make absolutely sure the data is flatten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f4388-121d-42a0-aa89-f52048da576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660c2bf5-29c6-451e-af54-893849528056",
   "metadata": {},
   "source": [
    "# 2. Build social networks of retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df9e2ad",
   "metadata": {},
   "source": [
    "First load the timelines and users from the files, parse the creation date as datetime and convert the IDs to srings to avoid int overflows. Use `pandas` [`read_csv`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) to do so. Especcialy look at the keyword arguments `dtype` and `parse_dates`.\n",
    "\n",
    " Since the `referenced_tweets` field contains a list of dictionaries that is stored as a string, we need to parse it first to restore its structure as list of dictionaries to interact with it. For this you can use a combination of pythons [`eval`](https://docs.python.org/3/library/functions.html#eval) function and `pandas` [`apply`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html) method. This function takes a string and evaluates it as a python expression. For example if you have following String:\n",
    "```\n",
    "some_string_with_a_dict = '{\"first_key\": \"first_value\",\n",
    "                            \"second_key\": \"second_value\",\n",
    "                            \"third_key\": \"third_value\",}'\n",
    "```\n",
    "And use `eval` on it like the following:\n",
    "```\n",
    "usable_dictionary_from_string = eval(some_string_with_a_dict)\n",
    "```\n",
    "You get the dictionary as a python local usable dictonary. Try it out!\n",
    "Now you can convert every `\"referenced_tweets\"` field in the dataset to usable python expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731d605d-3e1c-4237-8442-6fcb73074dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a987f77-803b-438a-8e00-d35786dd8ae4",
   "metadata": {},
   "source": [
    "The field `referenced_tweets` currently contains a list where each entry is a tweet object (since we requested the expansion on the field `referenced_tweets.id`.\n",
    "\n",
    "To construct our retweet network, we need to know (a) whether a tweet was a retweet and (b) the ID of the account that posted the tweet that was retweeted. Below we define two functions that help us extract this information from the `referenced_tweets` field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce16548-973a-4d78-90d9-7111e8c9f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_retweet(entry):\n",
    "    '''Checks whether a tweet is a retweet'''\n",
    "    if entry != entry: # NaN check\n",
    "        return False\n",
    "    for reference in entry:\n",
    "        if reference[\"type\"] == \"retweeted\":\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_retweet_author(entry):\n",
    "    '''Returns the author ID of the retweeted tweet'''\n",
    "    if entry != entry: # NaN check\n",
    "        return np.nan\n",
    "    for reference in entry:\n",
    "        if reference[\"type\"] == \"retweeted\":\n",
    "            return reference[\"author_id\"]\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2348df86-bb5f-445f-a1e4-b4d1a7e3944d",
   "metadata": {},
   "source": [
    "Apply the functions `check_retweet()` and `get_retweet_author` to the column `referenced_tweets` and create two new columns `retweeted` and `retweet_user_id` containing the relevant information. Again you can use `pandas` [`apply`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d217d6-6a89-4f08-9beb-847ff6a07805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa4746b-96d1-43e8-bac8-7ac92cfb27fa",
   "metadata": {},
   "source": [
    "Filter the tweets in the timelines such that you only retain retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afadf983-11f3-415c-bc5e-850ec736a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3d33b7-25ff-4907-a765-89da6634710c",
   "metadata": {},
   "source": [
    "Now filter the timelines such that the `retweet_user_id` is one of the user IDs in the user list. Use `pandas` [`isin`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html) method for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87fd91-cd68-4efa-9230-88cff7dce374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0a5575",
   "metadata": {},
   "source": [
    "Now finaly we can start to create the Graph, start by creating an empty graph with `networkx`. See [here](https://networkx.org/documentation/stable/reference/introduction.html#graph-creation) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a67723-cb41-42be-992e-1c81ecaaea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94116f1c-7aa7-4be9-87a3-69f9d40f4212",
   "metadata": {},
   "source": [
    "To build the retweet network, we have to fill the empty graph object we just created with nodes and edges. For this purpose, we prepare a list of nodes and their attributes and a list of edges.\n",
    "\n",
    "First, construct a list of vertices (nodes) and node attributes containing the user ids,  screen_names, and the **political party label** of the vertices. Remove all users without a party. Each entry of the list has the following form: \n",
    "\n",
    "`(id, {\"username\":username, \"party\":party})`\n",
    "\n",
    "Use the function [`add_nodes_from`](https://networkx.org/documentation/stable/reference/classes/generated/networkx.Graph.add_nodes_from.html) provided by `networkx` to add the nodes to the graph. \n",
    "\n",
    "Then build a list of edges where every edge is a pair of two users that exchanged at least one retweet with each other (regardless of the direction, remove all duplicate entries). Each entry of the list has the following form:  \n",
    "\n",
    "`(author_id_1, author_id_2)`\n",
    "\n",
    "Use the function [`add_edges_from`](https://networkx.org/documentation/stable/reference/classes/generated/networkx.Graph.add_edges_from.html) provided by `networkx` to add the edges to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfe5c8e-a0e3-48b9-a750-a39dc9db196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b97ed3-09ef-4cce-a2b7-7d176fe99013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d5b887",
   "metadata": {},
   "source": [
    "Visualize the graph - this is very ugly!\n",
    "Use [`draw_networkx`](https://networkx.org/documentation/stable/reference/generated/networkx.drawing.nx_pylab.draw_networkx.html) for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5240f4f3-df85-49b6-8b5c-6907b41c44fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f9f1b8-1b55-43b5-bc37-7389716008d5",
   "metadata": {},
   "source": [
    "# 3. Calculate graph assortativity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083ad210-6321-4625-9732-7da2c639da9d",
   "metadata": {},
   "source": [
    "Use the function [`attribute_assortativity_coefficient`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.assortativity.attribute_assortativity_coefficient.html) of `networkx` to calculate the assortativity with respect to party labels. How high is the value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eed1868-86cc-4752-b88a-b8a15e6cdfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbc8610-98e4-44e3-8774-ccf7d4e54922",
   "metadata": {},
   "source": [
    "To see if the assortativity value fits your expectations, use the function [`draw_networkx`](https://networkx.org/documentation/stable/reference/generated/networkx.drawing.nx_pylab.draw_networkx.html) to plot the network coloring each node according to the political party label of the politician. Does the pattern of colors fit the value of assortativity?\n",
    "\n",
    "Hint 1: use the optional function parameters `nodelist` and `node_color` to pass a list of nodes and a list of corresponding colors to the drawing function.  \n",
    "Hint 2: you can use one of [matplotlibs categorical color maps](https://matplotlib.org/stable/tutorials/colors/colormaps.html) to get a nice series of distinct colors for the parties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46f1c3-8297-4773-8689-b0d391b9a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a80be4e-32e1-476e-8e58-69b9e4b96976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399248d1-6cdc-46df-a15e-93c54393ae28",
   "metadata": {},
   "source": [
    "# 4. Permutation tests\n",
    "\n",
    "The above result looks assortative, but how can we test if it could have happened at random and not because of party identity? Here were are going to test it with a permutation test.\n",
    "\n",
    "First, let's run a permutation. Perform the same assortativity calculation as above but permuting the party labels of nodes. You can do this very efficiently by using `pandas` [`sample`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) function.\n",
    "\n",
    "Also set the party for each node as node attribute by using [`set_node_attribute`](https://networkx.org/documentation/stable/reference/generated/networkx.classes.function.set_node_attributes.html) (be carefull the parties are now permuted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7c449-46b0-42a3-be31-0100ac8eb962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349eda64-ccf7-4c28-881b-3021fbafad2c",
   "metadata": {},
   "source": [
    "Is the value much closer to zero?\n",
    "Repeat the calculation with 1000 permutations and plot the histogram of the resulting values. Add a line with the value of the assortativity without permutation. Is it far or close to the permuted values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ccb0e0-12bc-4917-acd2-3d10816498dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ec0ff-8744-4738-a95e-5d787b71822a",
   "metadata": {},
   "source": [
    "To be sure, let's calculate a p-value for the null hypothesis that the assortativity is zero and the alternative hypothesis that it is positive (what we expected):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb8e14e-8cad-4b08-9409-cbbeef8231a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c4e406-dd0a-4c3a-a47b-9c92fa3686d0",
   "metadata": {},
   "source": [
    "After looking at the above results, do you think it is likely that the assortativity we found in the data was produced by chance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d858242-9686-4a29-8b7e-7b50fdbea324",
   "metadata": {},
   "source": [
    "# 5. Community detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91874d7b-7a87-4b78-bb88-02c4fd3e62cc",
   "metadata": {},
   "source": [
    "Let's test if Twitter communities match political affiliations. Remove nodes with degree zero in the network and run the [Louvain community detection algorithm](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.louvain.louvain_communities.html). Visualize the result coloring nodes by community labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fcc80b-d3b7-47fa-94ef-44d05bc86fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4ed190-ff56-4210-a8ce-e366fa418ba4",
   "metadata": {},
   "source": [
    "Run the [`modularity`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.quality.modularity.html) function with the above community labels. Is it high enough to think that the network has a community structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e27434-547c-43b3-8c33-350fb3f6cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec818d-32f9-4c6f-be91-f475f3127da7",
   "metadata": {},
   "source": [
    "Repeat but using the party labels instead of the communities detected with Louvain. Is it higher or lower? How far is this modularity from the maximal one found with Louvain?\n",
    "\n",
    "For this iterate over the parties and filter a subset of users that is in the given party and in the graph. Add the ids of these partymembers (do not include any duplicates) and repeat this for all parties.\n",
    "\n",
    "Afterwards you can calculate the modularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71053121-99f9-4754-a69a-b182a0d672c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462a4aa1-0b8e-4c01-bb60-aaad998eabac",
   "metadata": {},
   "source": [
    "Finally, to understand which parties are represented in each community, build a data frame for nodes with two columns: one with the party label and another one with the community label. Use the [`groupby()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) function to print a contingency table. Which party or parties compose each community?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936a63bc-a71d-4228-822c-f8777c6654e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495e2320-8af1-4a72-b50e-66ce0efdbce6",
   "metadata": {},
   "source": [
    "# To learn more\n",
    "* How well can you predict the party of a politician from its neighbors in the network? Here you can use the rule of predicting the party as the majority party among its neighbors and evaluate the accuracy of this approach.\n",
    "* What would be the results if we use the network of replies? Do you expect assortativity and modularity to be higher or lower?\n",
    "* If you retrieved data of follower links, you can repeat the above analysis for undirected following relationships. Do you expect a higher or lower assortativity?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 10 2021, 00:03:59) \n[GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
